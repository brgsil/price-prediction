{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmLSaWxwz05m11fqKLqn8A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bruno-GSilva/price-prediction/blob/main/model_2/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDflnFJwNNz_"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyZJT2yrNiQ8"
      },
      "source": [
        "### Mount Drive to access data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV4-EmidNK9Z",
        "outputId": "78663173-38ed-453d-f5d1-66a688205bc1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7vNgf7yXxUa"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgCFEpoqUHjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c8518b-efd2-4125-8746-29b31c1096e3"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.functional import F\n",
        "import torch.optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "device = 'cpu' #torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smxeF74EXziJ"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_U4SZvmXkCS"
      },
      "source": [
        "class PriceDataset(Dataset):\n",
        "\n",
        "  def __init__(self, transform=None):\n",
        "\n",
        "    #Read CSV file\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/data/PETR4.SA.csv\", parse_dates=[0], infer_datetime_format=True)\n",
        "    df.dropna()\n",
        "\n",
        "    #Add collumn indicating when there is a time skip > 1 day\n",
        "    time_skip = [ 0 if index == 0 else 1 if (row['Date'] - df['Date'][index - 1]).days > 1 else 0 for index, row in df.iterrows() ]\n",
        "    df['Skip dates'] = time_skip\n",
        "\n",
        "    #Filter usefull collumns\n",
        "    df_filter = df.filter(['Open', 'High', 'Low', 'Close', 'Skip dates'])\n",
        "    data = df_filter.values\n",
        "\n",
        "    #Scale input\n",
        "    scaler = MinMaxScaler()\n",
        "    #data = scaler.fit_transform(data)\n",
        "\n",
        "    #Create samples\n",
        "    x_samples = []\n",
        "    y_samples = []\n",
        "    time_window = 30\n",
        "    for i in range (time_window, len(data)-time_window):\n",
        "      x_data = np.array(data[i-time_window : i])\n",
        "      scaled_x = scaler.fit_transform(x_data)\n",
        "      x_samples.append(scaled_x)\n",
        "      y_samples.append([1. if data[i+30,3] > data[i, 3] else 0.])\n",
        "\n",
        "    \n",
        "    x_samples, y_samples = np.array(x_samples), np.array(y_samples)\n",
        "    \n",
        "    #Transform int tensors\n",
        "    self.x_data = torch.from_numpy(x_samples)\n",
        "    self.y_data = torch.from_numpy(y_samples)\n",
        "    self.n_data = y_samples.shape[0]\n",
        "\n",
        "    #Set transform\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample = self.x_data[index], self.y_data[index]\n",
        "    if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_data"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN9ZM1L9NwlR"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSJe-_RmNwlS"
      },
      "source": [
        "class LSTMPrice(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "    super(LSTMPrice, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "    self.fc_1 = nn.Linear(hidden_size, 10)\n",
        "    self.fc_2 = nn.Linear(10, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size) #hidden state\n",
        "    c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size) #internal state\n",
        "    # Propagate input through LSTM\n",
        "    output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
        "    hn = hn[self.num_layers-1].view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
        "    out = F.relu(hn)\n",
        "    out = F.relu(self.fc_1(out)) #first Dense\n",
        "    out = self.fc_2(out) #Final Output\n",
        "\n",
        "    #Output with sigmoid\n",
        "    out = torch.sigmoid(out)\n",
        "\n",
        "    return out      \n"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOxMIbpuRmxR"
      },
      "source": [
        "## Preparing for trainning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvuAyNjUQo_p"
      },
      "source": [
        "dataset = PriceDataset()"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEXhf5gBQrSX"
      },
      "source": [
        "#Hyperparameters\n",
        "batch_size=4\n",
        "learning_rate=0.001\n",
        "input_size=dataset[0][0].shape[1]\n",
        "hidden_size=10\n",
        "num_epochs=2\n",
        "num_layers=2\n",
        "num_classes=dataset[0][1].shape[0]"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxNhVKLuRg9B"
      },
      "source": [
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry_pRLhWRrU5",
        "outputId": "5e08e68d-7fbd-4705-87d3-1ae793e27ef9"
      },
      "source": [
        "model = LSTMPrice(num_classes, input_size, hidden_size, num_layers)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "example_input = dataset[0][0].view(1,30,5)\n",
        "print(example_input)\n",
        "#model(example_input.float())"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.0000, 1.0000, 1.0000, 1.0000, 0.0000],\n",
            "         [0.5801, 0.5801, 0.5801, 0.5801, 0.0000],\n",
            "         [0.5078, 0.5078, 0.5078, 0.5078, 0.0000],\n",
            "         [0.4832, 0.4832, 0.4832, 0.4832, 0.0000],\n",
            "         [0.5155, 0.5155, 0.5155, 0.5155, 0.0000],\n",
            "         [0.6615, 0.6615, 0.6615, 0.6615, 1.0000],\n",
            "         [0.4832, 0.4832, 0.4832, 0.4832, 0.0000],\n",
            "         [0.4935, 0.4935, 0.4935, 0.4935, 0.0000],\n",
            "         [0.2894, 0.2894, 0.2894, 0.2894, 0.0000],\n",
            "         [0.3863, 0.3863, 0.3863, 0.3863, 0.0000],\n",
            "         [0.3062, 0.3062, 0.3062, 0.3062, 1.0000],\n",
            "         [0.3385, 0.3385, 0.3385, 0.3385, 0.0000],\n",
            "         [0.2894, 0.2894, 0.2894, 0.2894, 0.0000],\n",
            "         [0.2739, 0.2739, 0.2739, 0.2739, 0.0000],\n",
            "         [0.1279, 0.1279, 0.1279, 0.1279, 0.0000],\n",
            "         [0.0801, 0.0801, 0.0801, 0.0801, 1.0000],\n",
            "         [0.0801, 0.0801, 0.0801, 0.0801, 0.0000],\n",
            "         [0.1602, 0.1602, 0.1602, 0.1602, 0.0000],\n",
            "         [0.1124, 0.1124, 0.1124, 0.1124, 0.0000],\n",
            "         [0.1124, 0.1124, 0.1124, 0.1124, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
            "         [0.1279, 0.1279, 0.1279, 0.1279, 0.0000],\n",
            "         [0.2571, 0.2571, 0.2571, 0.2571, 0.0000],\n",
            "         [0.4509, 0.4509, 0.4509, 0.4509, 0.0000],\n",
            "         [0.6292, 0.6292, 0.6292, 0.6292, 0.0000],\n",
            "         [0.6770, 0.6770, 0.6770, 0.6770, 1.0000],\n",
            "         [0.8385, 0.8385, 0.8385, 0.8385, 0.0000],\n",
            "         [0.6770, 0.6770, 0.6770, 0.6770, 0.0000],\n",
            "         [0.4677, 0.4677, 0.4677, 0.4677, 0.0000],\n",
            "         [0.2416, 0.2416, 0.2416, 0.2416, 0.0000]]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "vPaHsELyX99i",
        "outputId": "720e3930-43ef-4b0e-e93f-6c9eac38de11"
      },
      "source": [
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):  \n",
        "        inputs = inputs.float()\n",
        "        labels = labels.view(batch_size, 1).float()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(inputs).float()\n",
        "        print(outputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss}')\n",
        "            print(outputs)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4531],\n",
            "        [0.4529],\n",
            "        [0.4526],\n",
            "        [0.4524]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[0.4512],\n",
            "        [0.4528],\n",
            "        [0.4527],\n",
            "        [0.4516]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[0.4525],\n",
            "        [0.4517],\n",
            "        [0.4535],\n",
            "        [   nan]], grad_fn=<SigmoidBackward>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-189-3b7adcf74f41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2891\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu7iQft-cm_9"
      },
      "source": [
        "torch.empty(3).random_(2).type()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}