{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPw5iDkYKOEkBLyVC9nerKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bruno-GSilva/price-prediction/blob/main/model_1/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mElz_UK7UDoC"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TADTktTqXrwr"
      },
      "source": [
        "### Mount Drive to access data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVhqccQqVweJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59105f13-8a39-43c4-9e56-7a1687383ca1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7vNgf7yXxUa"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgCFEpoqUHjJ"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smxeF74EXziJ"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_U4SZvmXkCS"
      },
      "source": [
        "class PriceDataset(Dataset):\n",
        "\n",
        "  def __init__(self, transform=None):\n",
        "\n",
        "    #Read CSV file\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/data/PETR4.SA.csv\", parse_dates=[0], infer_datetime_format=True)\n",
        "    df.dropna()\n",
        "\n",
        "    #Add collumn indicating when there is a time skip > 1 day\n",
        "    ttime_skip = [ 0 if index == 0 else 1 if (row['Date'] - df['Date'][index - 1]).days > 1 else 0 for index, row in df.iterrows() ]\n",
        "    df['Skip dates'] = time_skip\n",
        "\n",
        "    #Filter usefull collumns\n",
        "    df_filter = df.filter(['Open', 'High', 'Low', 'Close', 'Skip dates'])\n",
        "    data = df_filter.values\n",
        "\n",
        "    #Scale input\n",
        "    scaler = MinMaxScaler()\n",
        "    data = scaler.fit_transform(data)\n",
        "\n",
        "    #Create samples\n",
        "    x_samples = []\n",
        "    y_samples = []\n",
        "    for i in range (60, len(data)):\n",
        "      x_samples.append(data[i-60 : i])\n",
        "      y_samples.append(data[i,3])\n",
        "\n",
        "    x_samples, y_samples = np.array(x_samples), np.array(y_samples)\n",
        "\n",
        "    #Transform int tensors\n",
        "    self.x_data = torch.from_numpy(x_samples)\n",
        "    self.y_data = torch.from_numpy(y_samples)\n",
        "    self.n_data = y_samples.shape[0]\n",
        "\n",
        "    #Set transform\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample = self.x_data[index], self.y_data[index]\n",
        "    if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_data"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDK7i0ZmA6ho"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL7SkGneEkQy"
      },
      "source": [
        "# Fully connected neural network \n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.hidden_layers = []\n",
        "        for i in range(num_layers - 1):\n",
        "          self.hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        for i in range(len(hidden_layers)):\n",
        "          out = self.hidden_layers[i](out)\n",
        "          out = self.relu(out)\n",
        "\n",
        "        out = self.output_layer(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpxYJlp2AvrP"
      },
      "source": [
        "## Create DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNA7GhNsA0Le"
      },
      "source": [
        "class ToLinearTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return inputs.view(inputs.shape[0]*inputs.shape[1]), targets\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc-WpDEjAFuV"
      },
      "source": [
        "dataset = PriceDataset(transform=ToLinearTensor())\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)"
      ],
      "execution_count": 117,
      "outputs": []
    }
  ]
}